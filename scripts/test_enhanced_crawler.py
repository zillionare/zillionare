#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆæ–°é—»çˆ¬è™«æµ‹è¯•è„šæœ¬
"""

import os
import sys
import logging
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from scripts.enhanced_news_crawler import EnhancedNewsCrawler, NewsArticle

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def test_dependencies():
    """æµ‹è¯•ä¾èµ–åº“"""
    print("=== æµ‹è¯•ä¾èµ–åº“ ===")
    dependencies = [
        ('requests', 'HTTPè¯·æ±‚åº“'),
        ('feedparser', 'RSSè§£æåº“'),
        ('bs4', 'HTMLè§£æåº“'),
        ('markdownify', 'HTMLè½¬Markdownåº“'),
        ('yaml', 'YAMLé…ç½®æ–‡ä»¶åº“'),
        ('openai', 'OpenAI APIåº“'),
        ('slugify', 'æ–‡ä»¶åå®‰å…¨å¤„ç†åº“')
    ]
    
    all_ok = True
    for dep, desc in dependencies:
        try:
            __import__(dep)
            print(f"âœ“ {desc} ({dep})")
        except ImportError:
            print(f"âœ— {desc} ({dep}) - æœªå®‰è£…")
            all_ok = False
    
    # æµ‹è¯•OpenAI API Key
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key:
        print(f"âœ“ OpenAI API Keyå·²é…ç½®")
    else:
        print(f"âœ— OpenAI API Keyæœªé…ç½®")
        all_ok = False
    
    return all_ok

def test_article_filename():
    """æµ‹è¯•æ–‡ç« æ–‡ä»¶åç”Ÿæˆ"""
    print("\n=== æµ‹è¯•æ–‡ä»¶åç”Ÿæˆ ===")
    
    test_cases = [
        ("æ­£å¸¸è‹±æ–‡æ ‡é¢˜", "Normal English Title"),
        ("ä¸­æ–‡æ ‡é¢˜æµ‹è¯•", "ä¸­æ–‡æ ‡é¢˜æµ‹è¯•"),
        ("ç‰¹æ®Šå­—ç¬¦!@#$%^&*()", "Special Characters!@#$%^&*()"),
        ("å¾ˆé•¿çš„æ ‡é¢˜" * 20, "Very Long Title" * 20),
        ("", ""),  # ç©ºæ ‡é¢˜
    ]
    
    crawl_date = "2025-06-22"
    
    for desc, title in test_cases:
        article = NewsArticle(
            title=title,
            url="https://example.com/test",
            source="æµ‹è¯•æº"
        )
        
        filename = article.get_safe_filename(crawl_date)
        print(f"âœ“ {desc}: {filename}")
    
    return True

def test_openai_connection():
    """æµ‹è¯•OpenAIè¿æ¥"""
    print("\n=== æµ‹è¯•OpenAIè¿æ¥ ===")
    
    if not os.getenv("OPENAI_API_KEY"):
        print("âœ— è·³è¿‡OpenAIæµ‹è¯• - æœªé…ç½®API Key")
        return False
    
    try:
        import openai
        openai.api_key = os.getenv("OPENAI_API_KEY")
        
        # ç®€å•çš„æµ‹è¯•è¯·æ±‚
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "user", "content": "Hello, this is a test. Please respond with 'Test successful'."}
            ],
            max_tokens=10
        )
        
        result = response.choices[0].message.content.strip()
        print(f"âœ“ OpenAI APIè¿æ¥æˆåŠŸ: {result}")
        return True
        
    except Exception as e:
        print(f"âœ— OpenAI APIè¿æ¥å¤±è´¥: {e}")
        return False

def test_crawler_initialization():
    """æµ‹è¯•çˆ¬è™«åˆå§‹åŒ–"""
    print("\n=== æµ‹è¯•çˆ¬è™«åˆå§‹åŒ– ===")
    
    try:
        # ä¸´æ—¶è®¾ç½®API Keyï¼ˆå¦‚æœæ²¡æœ‰çš„è¯ï¼‰
        if not os.getenv("OPENAI_API_KEY"):
            os.environ["OPENAI_API_KEY"] = "test-key"
        
        crawler = EnhancedNewsCrawler("rss.yaml")
        print(f"âœ“ çˆ¬è™«åˆå§‹åŒ–æˆåŠŸ")
        print(f"  - é…ç½®æºæ•°é‡: {len(crawler.config.get('sources', []))}")
        print(f"  - ä¸´æ—¶ç›®å½•: {crawler.temp_dir}")
        
        return True
        
    except Exception as e:
        print(f"âœ— çˆ¬è™«åˆå§‹åŒ–å¤±è´¥: {e}")
        return False

def test_rss_parsing():
    """æµ‹è¯•RSSè§£æï¼ˆä½¿ç”¨çœŸå®æºï¼‰"""
    print("\n=== æµ‹è¯•RSSè§£æ ===")
    
    if not os.getenv("OPENAI_API_KEY"):
        print("âœ— è·³è¿‡RSSæµ‹è¯• - éœ€è¦OpenAI API Key")
        return False
    
    try:
        crawler = EnhancedNewsCrawler("rss.yaml")
        
        # åªæµ‹è¯•ç¬¬ä¸€ä¸ªæº
        sources = crawler.config.get('sources', [])
        if not sources:
            print("âœ— æ²¡æœ‰é…ç½®RSSæº")
            return False
        
        test_source = sources[0]
        print(f"æµ‹è¯•RSSæº: {test_source['name']}")
        
        articles = crawler._fetch_single_source(test_source)
        print(f"âœ“ æˆåŠŸè·å– {len(articles)} ç¯‡æ–‡ç« ")
        
        if articles:
            sample_article = articles[0]
            print(f"  - ç¤ºä¾‹æ–‡ç« : {sample_article.title}")
            print(f"  - é“¾æ¥: {sample_article.url}")
        
        return True
        
    except Exception as e:
        print(f"âœ— RSSè§£æå¤±è´¥: {e}")
        return False

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("å¢å¼ºç‰ˆæ–°é—»çˆ¬è™«æµ‹è¯•")
    print("=" * 50)
    
    tests = [
        ("ä¾èµ–åº“æ£€æŸ¥", test_dependencies),
        ("æ–‡ä»¶åç”Ÿæˆ", test_article_filename),
        ("OpenAIè¿æ¥", test_openai_connection),
        ("çˆ¬è™«åˆå§‹åŒ–", test_crawler_initialization),
        ("RSSè§£æ", test_rss_parsing),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âœ— {test_name} - å¼‚å¸¸: {e}")
            results.append((test_name, False))
    
    # æ€»ç»“
    print("\n" + "=" * 50)
    print("æµ‹è¯•ç»“æœæ€»ç»“:")
    
    passed = 0
    for test_name, result in results:
        status = "é€šè¿‡" if result else "å¤±è´¥"
        symbol = "âœ“" if result else "âœ—"
        print(f"{symbol} {test_name}: {status}")
        if result:
            passed += 1
    
    print(f"\næ€»è®¡: {passed}/{len(results)} é¡¹æµ‹è¯•é€šè¿‡")
    
    if passed == len(results):
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¢å¼ºç‰ˆçˆ¬è™«å¯ä»¥æ­£å¸¸ä½¿ç”¨ã€‚")
        return 0
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œä¾èµ–ã€‚")
        return 1

if __name__ == "__main__":
    sys.exit(main())
