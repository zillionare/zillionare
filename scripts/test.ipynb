{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9379f5e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "'pyarrow.parquet' is required when using `read_parquet(..., use_pyarrow=True)`.\nPlease install using the command `pip install pyarrow`.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m start = datetime.date(\u001b[32m2021\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)\n\u001b[32m      5\u001b[39m end = datetime.date(\u001b[32m2021\u001b[39m, \u001b[32m2\u001b[39m,\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m lb = \u001b[43mload_bars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m lb.tail()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.ipython/profile_default/startup/01-blog.py:151\u001b[39m, in \u001b[36mload_bars\u001b[39m\u001b[34m(start, end, universe, seed)\u001b[39m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    145\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(start, datetime.date)\n\u001b[32m    146\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(end, datetime.date)\n\u001b[32m    147\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(start, datetime.datetime)\n\u001b[32m    148\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(end, datetime.datetime)\n\u001b[32m    149\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mstart/end 必须为datetime.date类型\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m start >= datetime.date(\u001b[32m2005\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m end <= datetime.date(\u001b[32m2023\u001b[39m, \u001b[32m12\u001b[39m, \u001b[32m31\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_day_bars_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniverse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    153\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m暂不支持该时间区间\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.ipython/profile_default/startup/01-blog.py:884\u001b[39m, in \u001b[36m_load_day_bars_v2\u001b[39m\u001b[34m(start, end, universe)\u001b[39m\n\u001b[32m    881\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAllow time range: 2005-01-04 ~ 2023-12-29\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    883\u001b[39m path = data_home / \u001b[33m\"\u001b[39m\u001b[33mro/bars_1d_2005_2023_category.parquet\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m884\u001b[39m barss = \u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_pyarrow\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    886\u001b[39m all_symbols = barss[\u001b[33m\"\u001b[39m\u001b[33masset\u001b[39m\u001b[33m\"\u001b[39m].unique().sort()\n\u001b[32m    887\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(universe, \u001b[38;5;28mint\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/zillionare/lib/python3.12/site-packages/polars/_utils/deprecation.py:128\u001b[39m, in \u001b[36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> T:\n\u001b[32m    125\u001b[39m     _rename_keyword_argument(\n\u001b[32m    126\u001b[39m         old_name, new_name, kwargs, function.\u001b[34m__qualname__\u001b[39m, version\n\u001b[32m    127\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/zillionare/lib/python3.12/site-packages/polars/_utils/deprecation.py:128\u001b[39m, in \u001b[36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> T:\n\u001b[32m    125\u001b[39m     _rename_keyword_argument(\n\u001b[32m    126\u001b[39m         old_name, new_name, kwargs, function.\u001b[34m__qualname__\u001b[39m, version\n\u001b[32m    127\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/zillionare/lib/python3.12/site-packages/polars/io/parquet/functions.py:241\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(source, columns, n_rows, row_index_name, row_index_offset, parallel, use_statistics, hive_partitioning, glob, schema, hive_schema, try_parse_hive_dates, rechunk, low_memory, storage_options, credential_provider, retries, use_pyarrow, pyarrow_options, memory_map, include_file_paths, missing_columns, allow_missing_columns)\u001b[39m\n\u001b[32m    236\u001b[39m         msg = (\n\u001b[32m    237\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcannot use `hive_partitions` with `use_pyarrow=True`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    238\u001b[39m             \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mHint: Pass `pyarrow_options` instead with a \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpartitioning\u001b[39m\u001b[33m'\u001b[39m\u001b[33m entry.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    239\u001b[39m         )\n\u001b[32m    240\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_parquet_with_pyarrow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpyarrow_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpyarrow_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrechunk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrechunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_missing_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    251\u001b[39m     issue_deprecation_warning(\n\u001b[32m    252\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mthe parameter `allow_missing_columns` for `read_parquet` is deprecated. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUse the parameter `missing_columns` instead and pass one of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`(\u001b[39m\u001b[33m'\u001b[39m\u001b[33minsert\u001b[39m\u001b[33m'\u001b[39m\u001b[33m, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m)`.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    255\u001b[39m         version=\u001b[33m\"\u001b[39m\u001b[33m1.30.0\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    256\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/zillionare/lib/python3.12/site-packages/polars/io/parquet/functions.py:308\u001b[39m, in \u001b[36m_read_parquet_with_pyarrow\u001b[39m\u001b[34m(source, columns, storage_options, pyarrow_options, memory_map, rechunk)\u001b[39m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_parquet_with_pyarrow\u001b[39m(\n\u001b[32m    293\u001b[39m     source: \u001b[38;5;28mstr\u001b[39m\n\u001b[32m    294\u001b[39m     | Path\n\u001b[32m   (...)\u001b[39m\u001b[32m    306\u001b[39m     rechunk: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    307\u001b[39m ) -> DataFrame:\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     pyarrow_parquet = \u001b[43mimport_optional\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpyarrow.parquet\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43merr_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[43merr_suffix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mis required when using `read_parquet(..., use_pyarrow=True)`\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    313\u001b[39m     pyarrow_options = pyarrow_options \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[32m    315\u001b[39m     sources: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m | Path | IO[\u001b[38;5;28mbytes\u001b[39m] | \u001b[38;5;28mbytes\u001b[39m | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28mlist\u001b[39m[Path]] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/zillionare/lib/python3.12/site-packages/polars/dependencies.py:295\u001b[39m, in \u001b[36mimport_optional\u001b[39m\u001b[34m(module_name, err_prefix, err_suffix, min_version, min_err_prefix, install_message)\u001b[39m\n\u001b[32m    290\u001b[39m     suffix = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_suffix.strip(\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err_suffix \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    291\u001b[39m     err_message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + (\n\u001b[32m    292\u001b[39m         install_message\n\u001b[32m    293\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease install using the command `pip install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    294\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(err_message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m min_version:\n\u001b[32m    298\u001b[39m     min_version = parse_version(min_version)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: 'pyarrow.parquet' is required when using `read_parquet(..., use_pyarrow=True)`.\nPlease install using the command `pip install pyarrow`."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"scripts\")\n",
    "\n",
    "start = datetime.date(2021, 1, 1)\n",
    "end = datetime.date(2021, 2,1)\n",
    "lb = load_bars(start, end, 1)\n",
    "lb.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5b43ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-31 10:54:37.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mtushare\u001b[0m:\u001b[36m_connect\u001b[0m:\u001b[36m30\u001b[0m - \u001b[1mConnected to server tushare:5290\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ts_code  name report_date               report_title report_type  \\\n",
      "0    600000.SH  浦发银行    20241225          浦发银行：改革见效，基本面逐步夯实          一般   \n",
      "1    600000.SH  浦发银行    20241225          浦发银行：改革见效，基本面逐步夯实          一般   \n",
      "2    600000.SH  浦发银行    20241220        浦发银行：股东增持显信心，增长动能强劲          点评   \n",
      "3    600000.SH  浦发银行    20241220        浦发银行：股东增持显信心，增长动能强劲          点评   \n",
      "4    600000.SH  浦发银行    20241220        浦发银行：股东增持显信心，增长动能强劲          点评   \n",
      "..         ...   ...         ...                        ...         ...   \n",
      "121  600000.SH  浦发银行    20240320          浦发银行：业绩筑底，发力五篇大文章          点评   \n",
      "122  600000.SH  浦发银行    20240320          浦发银行：业绩筑底，发力五篇大文章          点评   \n",
      "123  600000.SH  浦发银行    20240320  浦发银行2023年业绩快报点评：业绩筑底，动能改善          点评   \n",
      "124  600000.SH  浦发银行    20240320  浦发银行2023年业绩快报点评：业绩筑底，动能改善          点评   \n",
      "125  600000.SH  浦发银行    20240320  浦发银行2023年业绩快报点评：业绩筑底，动能改善          点评   \n",
      "\n",
      "    classify org_name      author_name quarter       op_rt  ...         tp  \\\n",
      "0       一般报告       中金  王子瑜,李少萌,张帅帅,吕松涛  2024Q4  16727700.0  ...  4831400.0   \n",
      "1       一般报告       中金  王子瑜,李少萌,张帅帅,吕松涛  2025Q4  16585800.0  ...  5164700.0   \n",
      "2       一般报告     华福证券       张宇,郭其伟,付思雨  2024Q4  17350000.0  ...  5150000.0   \n",
      "3       一般报告     华福证券       张宇,郭其伟,付思雨  2025Q4  18130000.0  ...  5620000.0   \n",
      "4       一般报告     华福证券       张宇,郭其伟,付思雨  2026Q4  19120000.0  ...  6160000.0   \n",
      "..       ...      ...              ...     ...         ...  ...        ...   \n",
      "121     首份报告     中信建投           马鲲鹏,李晨  2024Q4  16099000.0  ...        NaN   \n",
      "122     首份报告     中信建投           马鲲鹏,李晨  2025Q4  16064700.0  ...        NaN   \n",
      "123     一般报告     浙商证券          梁凤洁,陈建宇  2023Q4  17343400.0  ...  4049100.0   \n",
      "124     一般报告     浙商证券          梁凤洁,陈建宇  2024Q4  16987400.0  ...  4055900.0   \n",
      "125     一般报告     浙商证券          梁凤洁,陈建宇  2025Q4  18140300.0  ...  4317400.0   \n",
      "\n",
      "            np    eps    pe    rd   roe  ev_ebitda rating max_price min_price  \n",
      "0    4263800.0  1.450  7.00  4.20  5.70       None   跑赢行业      None     11.52  \n",
      "1    4608600.0  1.570  6.50  4.60  5.90       None   跑赢行业      None     11.52  \n",
      "2    4660000.0  1.590  6.01   NaN  7.39       None     买入      None       NaN  \n",
      "3    5080000.0  1.730  5.51   NaN  7.62       None     买入      None       NaN  \n",
      "4    5570000.0  1.900  5.02   NaN  7.90       None     买入      None       NaN  \n",
      "..         ...    ...   ...   ...   ...        ...    ...       ...       ...  \n",
      "121  3353600.0  1.012  7.30   NaN   NaN       None     买入      None     12.10  \n",
      "122  3318100.0  1.002  7.40   NaN   NaN       None     买入      None     12.10  \n",
      "123  3670200.0  1.108  6.58  3.04  5.25       None     买入      None      9.06  \n",
      "124  3676400.0  1.110  6.57  3.04  5.06       None     买入      None      9.06  \n",
      "125  3913400.0  1.181  6.11  3.27  5.22       None     买入      None      9.06  \n",
      "\n",
      "[126 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "import tushare as ts\n",
    "pro = ts.pro_api()\n",
    "\n",
    "# 调取单只股票盈利预测（2024-01-01 至 2024-12-31）\n",
    "df = pro.report_rc(ts_code=\"600000.SH\", start_date=\"20240101\", end_date=\"20241231\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac8abaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1085 541\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "path = Path(\"~/workspace/zillionare/max-dama.srt\").expanduser()\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "timestamps = [\"00:00:00.000\"]\n",
    "for i in range(len(lines)):\n",
    "    if re.match(r\"^\\d+:\\d+\", lines[i]):\n",
    "        time = lines[i].split(\":\")\n",
    "        mm = int(time[0])\n",
    "        ss = int(time[1])\n",
    "        timestamps.append(f\"00:{mm:02d}:{ss:02d}.000\")\n",
    "\n",
    "timestamps.append(\"00:54:55,000\")\n",
    "\n",
    "print(len(lines), len(timestamps))\n",
    "j = 0\n",
    "m = 0\n",
    "buffers = []\n",
    "for i in range(len(lines)):\n",
    "    line = lines[i]\n",
    "    if re.match(r\"^\\d+:\\d+\", line):\n",
    "        j += 1\n",
    "        buffers.append(f\"\\n{j}\\n\")\n",
    "        line = timestamps[j] + \" --> \" + timestamps[j+1] + \"\\n\"\n",
    "        buffers.append(line)\n",
    "        continue\n",
    "    \n",
    "    buffers.append(line)\n",
    "    if len(buffers) > 100:\n",
    "        m += 1\n",
    "        to = path.parent / f\"srt/{m:02d}.srt\"\n",
    "        with open(to, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.writelines(buffers)\n",
    "            buffers = []\n",
    "\n",
    "to = path.parent / f\"srt/{m:02d}.srt\"\n",
    "if len(buffers) > 0:\n",
    "    with open(to, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.writelines(buffers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3b31447f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1, 'name': 'Fred'}, {'id': 2, 'name': 'Wilma'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite_utils as su\n",
    "\n",
    "db = su.Database(\":memory:\")\n",
    "\n",
    "db[\"users\"].insert_all([{\"id\": 1, \"name\": \"Fred\"}, {\"id\": 2, \"name\": \"Wilma\"}])\n",
    "list(db[\"users\"].rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf53a4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fred</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Wilma</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Barney</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    name   age\n",
       "0   1    Fred   NaN\n",
       "1   2   Wilma   NaN\n",
       "2   3  Barney  10.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[\"users\"].insert({\"id\": 3, \"name\": \"Barney\", \"age\": 10}, alter=True)\n",
    "\n",
    "pd.DataFrame(db[\"users\"].rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17d10ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, asdict, fields\n",
    "import types\n",
    "import sqlite_utils as su\n",
    "from enum import IntEnum\n",
    "import datetime\n",
    "\n",
    "def _dataclass_to_schema(model) -> dict:\n",
    "    \"\"\"类方法：解析当前 dataclass 为 fastlite 兼容的 schema 字典\"\"\"\n",
    "    schema = {}\n",
    "\n",
    "    for f in fields(model):\n",
    "        if f.type in (str, int, float, bool):\n",
    "            schema[f.name] = f.type\n",
    "        # 处理所有联合类型（Union[A, B] 和 A | B 语法）\n",
    "        elif (\n",
    "            hasattr(f.type, \"__origin__\") and f.type.__origin__ is Union\n",
    "        ) or isinstance(f.type, types.UnionType):\n",
    "            # 提取非 None 的类型\n",
    "            non_none_types = [t for t in f.type.__args__ if t is not type(None)]\n",
    "            if non_none_types:\n",
    "                base_type = non_none_types[0]\n",
    "                schema[f.name] = (\n",
    "                    base_type if base_type in (str, int, float, bool) else str\n",
    "                )\n",
    "            else:\n",
    "                schema[f.name] = str\n",
    "        elif isinstance(f.type, type) and issubclass(f.type, IntEnum):\n",
    "            schema[f.name] = int\n",
    "        else:\n",
    "            schema[f.name] = str\n",
    "    return schema\n",
    "\n",
    "def create_tables(db: su.Database, model):\n",
    "    \"\"\"初始化表结构\n",
    "    \n",
    "    在 sqlite_utils 中，创建表结构并非必须；但会导致sqlite-utils 无法准确判断类型。\n",
    "    \"\"\"\n",
    "    table = model.__table__\n",
    "    pk = model.__pk__\n",
    "\n",
    "    t: su.db.Table = db[table] # type: ignore\n",
    "    t.create(_dataclass_to_schema(model), pk=pk)\n",
    "\n",
    "    if model.__indices__ is not None:\n",
    "        indexes, is_unique = model.__indices__\n",
    "        t.create_index(indexes, unique=is_unique)\n",
    "\n",
    "class Gender(IntEnum):\n",
    "    MALE = 1\n",
    "    FEMALE = 2\n",
    "\n",
    "@dataclass\n",
    "class User:\n",
    "    __table__ = \"users\"\n",
    "    __pk__ = \"id\"\n",
    "    __indices__ = ([\"name\"], False)\n",
    "    id: int\n",
    "    name: str\n",
    "    birth: datetime.date\n",
    "    gender: Gender\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if isinstance(self.birth, str):\n",
    "            self.birth = datetime.date.fromisoformat(self.birth)\n",
    "        if isinstance(self.gender, int):\n",
    "            self.gender = Gender(self.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d5cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = su.Database(memory=True)\n",
    "\n",
    "create_tables(db, User)\n",
    "\n",
    "user = User(id=1, \n",
    "            name=\"Alice\", \n",
    "            birth=datetime.date(2020, 1, 1), \n",
    "            gender=Gender.FEMALE)\n",
    "\n",
    "# 增加一条记录\n",
    "db[\"users\"].insert(asdict(user))\n",
    "\n",
    "# 增加记录，如果存在，则进行更新\n",
    "db[\"users\"].upsert(asdict(user), pk=\"id\")\n",
    "\n",
    "# 上述语句相当于\n",
    "db[\"users\"].update(1, {\"birth\": datetime.date(2020, 1, 20)})\n",
    "\n",
    "# 通过主键查询刚修改的记录，生日将变为2020-01-20\n",
    "db[\"users\"].get(1)\n",
    "\n",
    "# 返回所有记录\n",
    "list(db[\"users\"].rows)\n",
    "\n",
    "# 返回所有记录，转换为 DataFrame。这里 pandas/polars 都支持\n",
    "pd.DataFrame(db[\"users\"].rows)\n",
    "\n",
    "# 按条件查询，使用 rows_where方法\n",
    "list(db[\"users\"].rows_where(\"gender = ?\", (Gender.FEMALE,)))\n",
    "\n",
    "# 当然，我们也可以使用 db.query 方法,显然不如上一种方法简洁\n",
    "list(db.query(\"SELECT * FROM users WHERE gender = ?\", (Gender.FEMALE,)))\n",
    "\n",
    "# 按条件删除记录，使用 delete_where 方法\n",
    "db[\"users\"].delete_where(\"id = ?\", (10,))\n",
    "\n",
    "# 按id 删除，使用 delete 方法\n",
    "db[\"users\"].delete(1)\n",
    "\n",
    "# 查询数据库中的记录数，此时应该为0\n",
    "db[\"users\"].count\n",
    "\n",
    "# 删除user 表，使用 drop 方法\n",
    "db[\"users\"].drop()\n",
    "\n",
    "# 确认表已删除，使用 tables属性。此时应该返回空列表\n",
    "db.tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b92aabcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "User(id=1, name='Alice', birth=datetime.date(2020, 1, 1), gender=<Gender.FEMALE: 2>)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_from_db = User(**list(db[\"users\"].rows)[0])\n",
    "user_from_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5378d66e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1, 'name': 'Alice', 'birth': '2020-01-01', 'gender': 2}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(db[\"users\"].rows)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5d11e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zillionare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
