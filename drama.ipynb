{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eea02917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>ECI</th>\n",
       "      <th>y</th>\n",
       "      <th>A_1</th>\n",
       "      <th>A_2</th>\n",
       "      <th>A_3</th>\n",
       "      <th>A_4</th>\n",
       "      <th>A_5</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>...</th>\n",
       "      <th>K_1</th>\n",
       "      <th>K_2</th>\n",
       "      <th>K_3</th>\n",
       "      <th>K_4</th>\n",
       "      <th>K_5</th>\n",
       "      <th>L_1</th>\n",
       "      <th>L_2</th>\n",
       "      <th>L_3</th>\n",
       "      <th>L_4</th>\n",
       "      <th>L_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-08-24</td>\n",
       "      <td>28826434</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-08-25</td>\n",
       "      <td>28826434</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-08-26</td>\n",
       "      <td>28826434</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-08-27</td>\n",
       "      <td>28826434</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-08-28</td>\n",
       "      <td>28826434</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       start       ECI  y  A_1  A_2  A_3  A_4  A_5  B_1  B_2  ...  K_1  K_2  \\\n",
       "0 2025-08-24  28826434  0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1 2025-08-25  28826434  0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0   \n",
       "2 2025-08-26  28826434  0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  1.0   \n",
       "3 2025-08-27  28826434  0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  1.0   \n",
       "4 2025-08-28  28826434  0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  1.0   \n",
       "\n",
       "   K_3  K_4  K_5  L_1  L_2  L_3  L_4  L_5  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "def rename_columns(data):\n",
    "    start = 3\n",
    "\n",
    "    # Save original tail column names before renaming\n",
    "    orig_cols = list(data.columns)\n",
    "    orig_tail = orig_cols[start:]\n",
    "\n",
    "    tail_count = max(0, data.shape[1] - start)\n",
    "    new_tail = list(string.ascii_uppercase[:tail_count]) \n",
    "\n",
    "    data.columns = [\"start\", \"ECI\", \"y\"] + new_tail\n",
    "\n",
    "    # Build mapping from letter to original column name for later decoding\n",
    "    letter_to_source = {new_tail[i]: orig_tail[i] for i in range(len(new_tail))}\n",
    "    # Attach mapping to DataFrame attrs to survive through later transforms\n",
    "    data.attrs['letter_to_source'] = letter_to_source\n",
    "    return data\n",
    "\n",
    "def expand_data(df: pd.DataFrame, n: int) -> pd.DataFrame:\n",
    "    if n <= 0:\n",
    "        # If no lag requested, just keep base columns\n",
    "        base_cols = [c for c in ['start', 'ECI', 'y'] if c in df.columns]\n",
    "        return df[base_cols].copy()\n",
    "\n",
    "    cols = list(df.columns)\n",
    "    # Prefer contiguous tail starting from 'A' (output of rename_columns)\n",
    "    if 'A' in cols:\n",
    "        start_idx = cols.index('A')\n",
    "        feat_cols = cols[start_idx:]\n",
    "    else:\n",
    "        # Fallback: uppercase letter-like column names in original order (A, B, ..., AA, AB, ...)\n",
    "        feat_candidates = {c for c in cols if c.isalpha() and c.upper() == c}\n",
    "        feat_cols = [c for c in cols if c in feat_candidates]\n",
    "\n",
    "    base_cols = [c for c in ['start', 'ECI', 'y'] if c in df.columns]\n",
    "\n",
    "    # Build lag features with vectorized shift (efficient, no Python loops over rows)\n",
    "    out = {}\n",
    "    for col in feat_cols:\n",
    "        s = df[col]\n",
    "        for k in range(1, n + 1):\n",
    "            out[f'{col}_{k}'] = s.shift(k)\n",
    "\n",
    "    features = pd.DataFrame(out, index=df.index)\n",
    "    res = pd.concat([df[base_cols], features], axis=1)\n",
    "\n",
    "    # Propagate and build decoding map for lagged features\n",
    "    letter_to_source = df.attrs.get('letter_to_source', {})\n",
    "    feature_decode = {}\n",
    "    for col in feat_cols:\n",
    "        src = letter_to_source.get(col, col)\n",
    "        for k in range(1, n + 1):\n",
    "            feature_decode[f'{col}_{k}'] = {'source': src, 'lag': k}\n",
    "    res.attrs['letter_to_source'] = letter_to_source\n",
    "    res.attrs['feature_decode'] = feature_decode\n",
    "    trimmed = res.iloc[n:].reset_index(drop=True)\n",
    "    trimmed.attrs['letter_to_source'] = letter_to_source\n",
    "    trimmed.attrs['feature_decode'] = feature_decode\n",
    "    return trimmed\n",
    "\n",
    "def prepare_data():\n",
    "    data = pd.read_excel(\"drama.xlsx\")\n",
    "    df_ = rename_columns(data)\n",
    "    return expand_data(df_, 5)\n",
    "\n",
    "df = prepare_data()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ac60569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature      original_feature  importance\n",
      "0      K_2       是否弱覆盖（0，1）_lag2    0.214508\n",
      "1      K_1       是否弱覆盖（0，1）_lag1    0.154559\n",
      "2      A_1       是否过覆盖（0，1）_lag1    0.000000\n",
      "3      I_5  是否邻区配置数据异常（0，1）_lag5    0.000000\n",
      "4      G_3    小区eRAB拥塞（0,1）_lag3    0.000000\n",
      "5      G_4    小区eRAB拥塞（0,1）_lag4    0.000000\n",
      "6      G_5    小区eRAB拥塞（0,1）_lag5    0.000000\n",
      "7      H_1      是否干扰小区（0，1）_lag1    0.000000\n",
      "8      H_2      是否干扰小区（0，1）_lag2    0.000000\n",
      "9      H_3      是否干扰小区（0，1）_lag3    0.000000\n",
      "10     H_4      是否干扰小区（0，1）_lag4    0.000000\n",
      "11     H_5      是否干扰小区（0，1）_lag5    0.000000\n",
      "12     I_1  是否邻区配置数据异常（0，1）_lag1    0.000000\n",
      "13     I_2  是否邻区配置数据异常（0，1）_lag2    0.000000\n",
      "14     I_3  是否邻区配置数据异常（0，1）_lag3    0.000000\n",
      "15     I_4  是否邻区配置数据异常（0，1）_lag4    0.000000\n",
      "16     J_1  小区过覆盖导致高负荷（0,1）_lag1    0.000000\n",
      "17     A_2       是否过覆盖（0，1）_lag2    0.000000\n",
      "18     J_2  小区过覆盖导致高负荷（0,1）_lag2    0.000000\n",
      "19     J_3  小区过覆盖导致高负荷（0,1）_lag3    0.000000\n",
      "20     J_4  小区过覆盖导致高负荷（0,1）_lag4    0.000000\n",
      "21     J_5  小区过覆盖导致高负荷（0,1）_lag5    0.000000\n",
      "22     K_3       是否弱覆盖（0，1）_lag3    0.000000\n",
      "23     K_4       是否弱覆盖（0，1）_lag4    0.000000\n",
      "24     K_5       是否弱覆盖（0，1）_lag5    0.000000\n",
      "25     L_1    是否同频重叠覆盖（0，1）_lag1    0.000000\n",
      "26     L_2    是否同频重叠覆盖（0，1）_lag2    0.000000\n",
      "27     L_3    是否同频重叠覆盖（0，1）_lag3    0.000000\n",
      "28     L_4    是否同频重叠覆盖（0，1）_lag4    0.000000\n",
      "29     G_2    小区eRAB拥塞（0,1）_lag2    0.000000\n",
      "   feature  importance      original_feature\n",
      "0      K_2    0.214508       是否弱覆盖（0，1）_lag2\n",
      "1      K_1    0.154559       是否弱覆盖（0，1）_lag1\n",
      "2      A_1    0.000000       是否过覆盖（0，1）_lag1\n",
      "3      I_5    0.000000  是否邻区配置数据异常（0，1）_lag5\n",
      "4      G_3    0.000000    小区eRAB拥塞（0,1）_lag3\n",
      "5      G_4    0.000000    小区eRAB拥塞（0,1）_lag4\n",
      "6      G_5    0.000000    小区eRAB拥塞（0,1）_lag5\n",
      "7      H_1    0.000000      是否干扰小区（0，1）_lag1\n",
      "8      H_2    0.000000      是否干扰小区（0，1）_lag2\n",
      "9      H_3    0.000000      是否干扰小区（0，1）_lag3\n",
      "10     H_4    0.000000      是否干扰小区（0，1）_lag4\n",
      "11     H_5    0.000000      是否干扰小区（0，1）_lag5\n",
      "12     I_1    0.000000  是否邻区配置数据异常（0，1）_lag1\n",
      "13     I_2    0.000000  是否邻区配置数据异常（0，1）_lag2\n",
      "14     I_3    0.000000  是否邻区配置数据异常（0，1）_lag3\n",
      "15     I_4    0.000000  是否邻区配置数据异常（0，1）_lag4\n",
      "16     J_1    0.000000  小区过覆盖导致高负荷（0,1）_lag1\n",
      "17     A_2    0.000000       是否过覆盖（0，1）_lag2\n",
      "18     J_2    0.000000  小区过覆盖导致高负荷（0,1）_lag2\n",
      "19     J_3    0.000000  小区过覆盖导致高负荷（0,1）_lag3\n",
      "20     J_4    0.000000  小区过覆盖导致高负荷（0,1）_lag4\n",
      "21     J_5    0.000000  小区过覆盖导致高负荷（0,1）_lag5\n",
      "22     K_3    0.000000       是否弱覆盖（0，1）_lag3\n",
      "23     K_4    0.000000       是否弱覆盖（0，1）_lag4\n",
      "24     K_5    0.000000       是否弱覆盖（0，1）_lag5\n",
      "25     L_1    0.000000    是否同频重叠覆盖（0，1）_lag1\n",
      "26     L_2    0.000000    是否同频重叠覆盖（0，1）_lag2\n",
      "27     L_3    0.000000    是否同频重叠覆盖（0，1）_lag3\n",
      "28     L_4    0.000000    是否同频重叠覆盖（0，1）_lag4\n",
      "29     G_2    0.000000    小区eRAB拥塞（0,1）_lag2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def train_xgb_and_rank_features(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str = \"y\",\n",
    "    drop_cols=(\"start\", \"ECI\"),\n",
    "    importance_type: str = \"gain\",  # 'gain' | 'weight' | 'cover' | 'total_gain' | 'total_cover'\n",
    "    n_estimators: int = 400,\n",
    "    max_depth: int = 5,\n",
    "    learning_rate: float = 0.05,\n",
    "    subsample: float = 0.8,\n",
    "    colsample_bytree: float = 0.8,\n",
    "    reg_lambda: float = 1.0,\n",
    "    random_state: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train an XGBoost classifier and return sorted feature importances.\n",
    "    - Features: all columns except [drop_cols + target_col]\n",
    "    - Target: y (auto-encode to integers if not numeric)\n",
    "    \"\"\"\n",
    "    # 1) Build X, y\n",
    "    feat_cols = [c for c in df.columns if c not in set(drop_cols) | {target_col}]\n",
    "    X = df[feat_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "    y = pd.to_numeric(df[target_col], errors=\"ignore\")\n",
    "\n",
    "    # 2) Drop rows with NaN in X or y to ensure clean training data\n",
    "    mask = X.notna().all(axis=1) & pd.notna(y)\n",
    "    X, y = X.loc[mask], y.loc[mask]\n",
    "\n",
    "    # 3) Encode non-numeric y to category codes for classification\n",
    "    if not np.issubdtype(y.dtype, np.number):\n",
    "        y = y.astype(\"category\").cat.codes\n",
    "\n",
    "    classes = np.unique(y)\n",
    "    num_class = len(classes)\n",
    "    objective = \"binary:logistic\" if num_class == 2 else \"multi:softprob\"\n",
    "\n",
    "    # 4) Construct classifier (only set num_class when > 2)\n",
    "    params = dict(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        learning_rate=learning_rate,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        reg_lambda=reg_lambda,\n",
    "        objective=objective,\n",
    "        eval_metric=\"logloss\" if num_class == 2 else \"mlogloss\",\n",
    "        n_jobs=0,\n",
    "        tree_method=\"hist\",\n",
    "        random_state=random_state,\n",
    "    )\n",
    "    if num_class > 2:\n",
    "        params[\"num_class\"] = num_class\n",
    "\n",
    "    clf = XGBClassifier(**params)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # 5) Get feature importance\n",
    "    booster = clf.get_booster()\n",
    "    score = booster.get_score(importance_type=importance_type)  \n",
    "    if score and not next(iter(score)).startswith(\"f\"):\n",
    "        # Good case: keys are real feature names\n",
    "        imp_df = pd.DataFrame([(name, score.get(name, 0.0)) for name in X.columns],\n",
    "                              columns=[\"feature\", \"importance\"])\n",
    "    else:\n",
    "        # Fallback: use sklearn-style importances aligned with columns\n",
    "        imp_df = pd.DataFrame({\"feature\": X.columns, \"importance\": clf.feature_importances_})\n",
    "\n",
    "    imp_df = imp_df.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "    return clf, imp_df\n",
    "\n",
    "clf, importance_df = train_xgb_and_rank_features(df, target_col=\"y\")\n",
    "\n",
    "# Decode feature names back to original column names with lag info if mapping is available\n",
    "letter_map = df.attrs.get('letter_to_source', {})\n",
    "feat_decode = df.attrs.get('feature_decode', {})\n",
    "\n",
    "def _decode(name: str) -> str:\n",
    "    info = feat_decode.get(name)\n",
    "    if isinstance(info, dict) and 'source' in info and 'lag' in info:\n",
    "        return f\"{info['source']}_lag{info['lag']}\"\n",
    "    # Fallback: try to parse Letter_Lag pattern\n",
    "    try:\n",
    "        letter, lag = name.split('_', 1)\n",
    "        return f\"{letter_map.get(letter, letter)}_lag{lag}\"\n",
    "    except Exception:\n",
    "        return name\n",
    "\n",
    "if isinstance(importance_df, pd.DataFrame) and 'feature' in importance_df.columns:\n",
    "    importance_df['original_feature'] = importance_df['feature'].map(_decode)\n",
    "    print(importance_df[[\"feature\", \"original_feature\", \"importance\"]].head(30))\n",
    "else:\n",
    "    print(importance_df.head(30))  # 查看前30个最重要特征(无解码映射时的回退)\n",
    "print(importance_df.head(30))  # 查看前30个最重要特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "616c661b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'是否过覆盖（0，1）'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.attrs['letter_to_source']['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a7cf7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zillionare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
